import cv2
import os
import time
import torch
import numpy as np
from sort import Sort
from tqdm import tqdm
import warnings
import csv  # ÊîæÂú®Êñá‰ª∂ÂºÄÂ§¥

warnings.filterwarnings("ignore", category=FutureWarning,
                        message=".*torch.cuda.amp.autocast.*")

BASE_DIR = os.path.dirname(os.path.abspath(__file__))
RIGHT_RATIO = 0.5
DETECTION_LINE_COLOR = (0, 0, 255)
DETECTION_LINE_THICKNESS = 2

def load_model_with_retry(retries=3, delay=5):
    model_path = os.path.join(BASE_DIR, 'yolov5s.pt')
    for attempt in range(retries):
        try:
            model = torch.hub.load('ultralytics/yolov5', 'custom', path=model_path)
            return model
        except Exception as e:
            print(f"Ê®°ÂûãÂä†ËΩΩÂ§±Ë¥•ÔºåÂ∞ùËØï {attempt + 1}/{retries}: {e}")
            if attempt < retries - 1:
                time.sleep(delay)
            else:
                raise

def detect_right_vehicles(frame, model, right_ratio):
    height, width = frame.shape[:2]
    right_boundary = int(width * (1 - right_ratio))
    results = model(frame)
    detections = []
    for *box, conf, cls in results.xyxy[0]:
        if conf > 0.5:
            x1, y1, x2, y2 = map(int, box)
            if (x1 + x2) / 2 > right_boundary:
                detections.append([x1, y1, x2, y2, conf.item()])
    return detections, right_boundary

def get_confidence_for_track(track_box, detections):
    x1, y1, x2, y2 = track_box
    for det in detections:
        dx1, dy1, dx2, dy2, det_conf = det
        cx, cy = (dx1+dx2)/2, (dy1+dy2)/2
        if x1 <= cx <= x2 and y1 <= cy <= y2:
            return det_conf
    return 0.0  # Â¶ÇÊûúÂÆûÂú®Êâæ‰∏çÂà∞ÔºåÂ∞±ËøîÂõû 0

def process_video(input_path, output_path, model):
    # 1) ÂàùÂßãÂåñ CSV Âπ∂ÂÜôÂÖ•Ë°®Â§¥
    output_csv_path = os.path.join(os.path.dirname(input_path), 'detection_output.csv')

    with open(output_csv_path, 'w', newline='') as csvfile:
        writer = csv.writer(csvfile)
        writer.writerow(['frame', 'x1', 'y1', 'x2', 'y2', 'track_id', 'confidence'])

    cap = cv2.VideoCapture(input_path)
    width  = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    fps    = cap.get(cv2.CAP_PROP_FPS)
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    frame_info_txt = os.path.join(os.path.dirname(input_path), 'frame_count.txt')
    with open(frame_info_txt, 'w') as f:
        f.write(f"{total_frames}\n")
    fourcc = cv2.VideoWriter_fourcc(*'mp4v')
    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))
    tracker = Sort(max_age=5, min_hits=3, iou_threshold=0.3)
    all_ids = set()


    with tqdm(total=total_frames, desc=f"Â§ÑÁêÜ {os.path.basename(input_path)}") as pbar:
        while True:
            ret, frame = cap.read()
            if not ret:
                break
            detections, right_boundary = detect_right_vehicles(frame, model, RIGHT_RATIO)

            # ÁîªÊ£ÄÊµãÂå∫Âüü
            # cv2.line(frame, (right_boundary, 0), (right_boundary, height),
            #          DETECTION_LINE_COLOR, DETECTION_LINE_THICKNESS)
            # cv2.putText(frame, "Detection Area", (right_boundary + 10, 30),
            #             cv2.FONT_HERSHEY_SIMPLEX, 0.7, DETECTION_LINE_COLOR, 2)

            dets_np = np.array(detections) if detections else np.empty((0, 5))
            tracks = tracker.update(dets_np)

            frame_index = int(cap.get(cv2.CAP_PROP_POS_FRAMES))
            for t in tracks:
                x1, y1, x2, y2, tid = t
                x1, y1, x2, y2, tid = map(int, (x1, y1, x2, y2, tid))
                all_ids.add(tid)

                # 2) ÊâæÂà∞Ëøô‰∏™ track ÂØπÂ∫îÁöÑÊ£ÄÊµãÁΩÆ‰ø°Â∫¶
                conf = get_confidence_for_track((x1, y1, x2, y2), detections)

                # 3) ÂÜôÂÖ• CSV
                with open(output_csv_path, 'a', newline='') as csvfile:
                    writer = csv.writer(csvfile)
                    writer.writerow([frame_index, x1, y1, x2, y2, tid, conf])

                # 4) ÁîªÊ°ÜÂíå ID
                cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)
                cv2.putText(frame, f'ID:{tid}', (x1, y1-10),
                            cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)

            out.write(frame)
            pbar.update(1)

    cap.release()
    out.release()
    print(f"\nËßÜÈ¢ë {os.path.basename(input_path)} ‰∏≠Âá∫Áé∞ÁöÑËΩ¶ËæÜ IDÔºö{sorted(all_ids)}")







def main():
    LAB3_DIR = os.path.join(BASE_DIR, r'D:\vehicle_tracking_new\vehicle_tracking\newnew\heiyeW2')
    subdirs = [os.path.join(LAB3_DIR, d) for d in os.listdir(LAB3_DIR)
               if os.path.isdir(os.path.join(LAB3_DIR, d))]

    if not subdirs:
        print(f"Lab3 ÁõÆÂΩï‰∏ãÊ≤°Êúâ‰ªª‰ΩïÂ≠êÊñá‰ª∂Â§π: {LAB3_DIR}")
        return

    print(f"ÊâæÂà∞ {len(subdirs)} ‰∏™Â≠êÊñá‰ª∂Â§πÔºåÂºÄÂßãÈÅçÂéÜ...")
    model = load_model_with_retry()

    for folder in subdirs:
        video_files = [f for f in os.listdir(folder)
                       if f.lower().endswith('.mp4') and f.lower().startswith("rgb")]
        if not video_files:
            print(f"‚è≠Ô∏è Â≠êÊñá‰ª∂Â§π‰∏≠Ê≤°Êúâ rgb ÂºÄÂ§¥ÁöÑËßÜÈ¢ë: {folder}")
            continue

        print(f"\nüìÅ ÂΩìÂâçÁõÆÂΩï: {folder}ÔºåRGB ËßÜÈ¢ëÊï∞Èáè: {len(video_files)}")
        for video_file in video_files:
            input_path  = os.path.join(folder, video_file)
            output_path = os.path.join(folder, f"right_tracked_{video_file}")
            print(f"üé¨ Ê≠£Âú®Â§ÑÁêÜ: {video_file}")
            start_time = time.time()
            try:
                process_video(input_path, output_path, model)
                elapsed = time.time() - start_time
                print(f"‚úîÔ∏è ÂÆåÊàê: {output_path}ÔºàËÄóÊó∂: {elapsed:.2f}ÁßíÔºâ")
            except Exception as e:
                print(f"‚ùå Â§ÑÁêÜÂ§±Ë¥•: {video_file} - ÈîôËØØ: {e}")

if __name__ == '__main__':
    main()
