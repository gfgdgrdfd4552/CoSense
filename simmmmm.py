import os
import time
import random
import weakref
import math
import carla
import json
import cv2
import numpy as np
import threading
import queue
from queue import Queue

# å¸¸é‡å®šä¹‰ä¼˜åŒ–
NUM_PARKED_VEHICLES = 5     # è¿åœè½¦è¾†æ•°é‡
NUM_SENSOR_VEHICLES = 10    # æ„ŸçŸ¥è½¦è¾†æ•°é‡
NUM_NORMAL_VEHICLES = 20    # æ™®é€šè½¦è¾†æ•°é‡
SIMULATION_TIME = 3600      # æ¨¡æ‹Ÿæ—¶é•¿(ç§’)
IMAGE_WIDTH = 640           # æ‘„åƒå¤´å›¾åƒå®½åº¦
IMAGE_HEIGHT = 480          # æ‘„åƒå¤´å›¾åƒé«˜åº¦
LANE_WIDTH = 3.5            # å•è½¦é“å®½åº¦(ç±³)
FPS = 30                    # è§†é¢‘å¸§ç‡
MAX_VIDEO_QUEUE_SIZE = 60   # è§†é¢‘é˜Ÿåˆ—æœ€å¤§å®¹é‡ï¼ˆ2ç§’ï¼‰

# é“è·¯åæ ‡ä¼˜åŒ–
STREET_START = carla.Location(x=80, y=15.2, z=0)
STREET_END = carla.Location(x=-10, y=15.2, z=0)
VEHICLE_LENGTH = 4.5        # å¹³å‡è½¦é•¿(ç±³)
VEHICLE_WIDTH = 2.0         # å¹³å‡è½¦å®½(ç±³)

# è¿åœä½ç½®
ILLEGAL_PARKING_POINT = carla.Location(x=15.39, y=9.76, z=0)

# è½¦é“ä¸­å¿ƒçº¿å®šä¹‰
LEFT_LANE_Y = 15.2 + LANE_WIDTH / 2   # å·¦è½¦é“ä¸­å¿ƒçº¿ y=17.95
RIGHT_LANE_Y = 15.2 - LANE_WIDTH / 2  # å³è½¦é“ä¸­å¿ƒçº¿ y=12.45

# æ„ŸçŸ¥è½¦è¾†é—´è·ï¼ˆç¡®ä¿å‰æ–¹æœ‰è½¦è¾†é®æŒ¡ï¼‰
SENSOR_VEHICLE_SPACING = 5.0  # æ„ŸçŸ¥è½¦è¾†é—´è·ï¼ˆç±³ï¼‰

class VideoWriterThread(threading.Thread):
    """å¼‚æ­¥è§†é¢‘å†™å…¥çº¿ç¨‹ï¼ˆæ”¯æŒRGBå’Œæ·±åº¦è§†é¢‘ï¼‰"""
    
    def __init__(self, vehicle_id):
        super().__init__()
        self.vehicle_id = vehicle_id
        self.save_dir = f'output/camera_images/vehicle_{vehicle_id}'
        os.makedirs(self.save_dir, exist_ok=True)
        
        # åˆå§‹åŒ–è§†é¢‘å†™å…¥å™¨
        timestamp = time.strftime("%Y%m%d_%H%M%S")
        
        # RGBè§†é¢‘å†™å…¥å™¨
        rgb_video_path = f'{self.save_dir}/rgb_recording_{timestamp}.mp4'
        fourcc = cv2.VideoWriter_fourcc(*'mp4v')
        self.rgb_writer = cv2.VideoWriter(rgb_video_path, fourcc, FPS, (IMAGE_WIDTH, IMAGE_HEIGHT))
        
        # æ·±åº¦è§†é¢‘å†™å…¥å™¨
        depth_video_path = f'{self.save_dir}/depth_recording_{timestamp}.mp4'
        self.depth_writer = cv2.VideoWriter(depth_video_path, fourcc, FPS, (IMAGE_WIDTH, IMAGE_HEIGHT))
        
        # å›¾åƒé˜Ÿåˆ—
        self.queue = queue.Queue(maxsize=MAX_VIDEO_QUEUE_SIZE)
        self.stop_event = threading.Event()
        self.daemon = True
        self.frame_count = 0
        
    def run(self):
        """çº¿ç¨‹ä¸»å‡½æ•°"""
        print(f"ğŸ“¹ Video writer started for vehicle {self.vehicle_id}")
        while not self.stop_event.is_set() or not self.queue.empty():
            try:
                # ä»é˜Ÿåˆ—è·å–å›¾åƒ
                rgb_array, depth_vis = self.queue.get(timeout=1.0)
                
                # å†™å…¥RGBè§†é¢‘
                self.rgb_writer.write(rgb_array)
                
                # å†™å…¥æ·±åº¦è§†é¢‘ï¼ˆåº”ç”¨ä¼ªå½©è‰²æ˜ å°„ï¼‰
                depth_colored = cv2.applyColorMap(depth_vis, cv2.COLORMAP_JET)
                self.depth_writer.write(depth_colored)
                
                self.queue.task_done()
                self.frame_count += 1
            except queue.Empty:
                continue
        
        # é‡Šæ”¾èµ„æº
        self.rgb_writer.release()
        self.depth_writer.release()
        print(f"ğŸ“¹ Video writer for vehicle {self.vehicle_id} released, wrote {self.frame_count} frames")
    
    def add_frame(self, rgb_array, depth_vis):
        """æ·»åŠ å¸§åˆ°é˜Ÿåˆ—"""
        if not self.stop_event.is_set():
            try:
                # å¦‚æœé˜Ÿåˆ—å·²æ»¡ï¼Œä¸¢å¼ƒæ—§å¸§
                if self.queue.full():
                    try:
                        self.queue.get_nowait()
                    except queue.Empty:
                        pass
                
                # å­˜å‚¨RGBå’Œæ·±åº¦å›¾åƒ
                self.queue.put_nowait((rgb_array.copy(), depth_vis.copy()))
            except Exception as e:
                print(f"âš ï¸ Error adding frame to video queue: {e}")

def setup_traffic_light(world):
    """åœ¨é“è·¯å‰æ–¹è®¾ç½®çº¢ç»¿ç¯å¹¶è®¾ä¸ºç»¿ç¯120ç§’"""
    try:
        # è·å–æ‰€æœ‰çº¢ç»¿ç¯
        all_traffic_lights = world.get_actors().filter('traffic.traffic_light*')
        
        # å¯»æ‰¾æœ€æ¥è¿‘ç›®æ ‡ä½ç½®çš„çº¢ç»¿ç¯
        target_light = None
        min_distance = float('inf')
        
        for traffic_light in all_traffic_lights:
            light_location = traffic_light.get_location()
            distance = light_location.distance(carla.Location(x=90.0, y=5.0, z=5.0))
            
            # å¯»æ‰¾é“è·¯å‰æ–¹çš„çº¢ç»¿ç¯ï¼ˆxåæ ‡å¤§äº80ä¸”è·ç¦»æœ€è¿‘ï¼‰
            if light_location.x > 80 and distance < min_distance:
                min_distance = distance
                target_light = traffic_light
                
        if target_light:
            # è®¾ç½®çº¢ç»¿ç¯çŠ¶æ€ä¸ºç»¿ç¯ï¼ŒæŒç»­120ç§’
            target_light.set_state(carla.TrafficLightState.Green)
            target_light.set_green_time(120.0)
            
            light_loc = target_light.get_location()
            print(f"âœ… Traffic light set to GREEN for 120 seconds at location: x={light_loc.x:.1f}, y={light_loc.y:.1f}")
            return target_light
        else:
            print("âš ï¸ No suitable traffic light found near the target road section")
            return None
            
    except Exception as e:
        print(f"âŒ Error setting up traffic light: {str(e)}")
        return None

class StreetMonitor:
    """é“è·¯ç›‘æ§å™¨"""

    @staticmethod
    def calculate_parking_positions():
        """åœ¨æŒ‡å®šä½ç½®(x=15.39, y=9.76)æ²¿ç€é“è·¯æ–¹å‘ç”Ÿæˆ5è¾†è¿åœè½¦è¾†"""
        parking_positions = []
        
        # è®¡ç®—é“è·¯æ–¹å‘å‘é‡
        direction = carla.Vector3D(
            x=STREET_END.x - STREET_START.x,
            y=STREET_END.y - STREET_START.y,
            z=0
        )
        road_length = math.sqrt(direction.x ** 2 + direction.y ** 2)
        if road_length > 0:
            direction = direction / road_length  # å•ä½åŒ–å‘é‡
        
        # è®¡ç®—æœå‘(ä¸é“è·¯æ–¹å‘ç›¸åŒ)
        yaw = math.degrees(math.atan2(direction.y, direction.x))
        
        # æ²¿ç€é“è·¯æ–¹å‘æ’åˆ—è½¦è¾†
        for i in range(NUM_PARKED_VEHICLES):
            # è®¡ç®—æ¯è¾†è½¦çš„åç§»é‡
            offset = direction * (i * (VEHICLE_LENGTH + 1.0))
            
            parking_pos = carla.Location(
                x=ILLEGAL_PARKING_POINT.x + offset.x,
                y=ILLEGAL_PARKING_POINT.y + offset.y,
                z=0.1
            )
            
            parking_positions.append(
                carla.Transform(parking_pos, carla.Rotation(yaw=yaw)))
            
        return parking_positions

    @staticmethod
    def is_on_street(location):
        """æ£€æŸ¥ä½ç½®æ˜¯å¦åœ¨ç›®æ ‡é“è·¯ä¸Š"""
        # ç®€å•è¾¹ç•Œæ£€æŸ¥ï¼ˆä¼˜åŒ–æ€§èƒ½ï¼‰
        if location.x < STREET_END.x or location.x > STREET_START.x:
            return False
        
        # æ£€æŸ¥yåæ ‡æ˜¯å¦åœ¨é“è·¯èŒƒå›´å†…
        return abs(location.y - STREET_START.y) <= LANE_WIDTH * 1.5

class VehicleRecorder:
    """è½¦è¾†æ•°æ®è®°å½•å™¨ï¼ˆä¼˜åŒ–ç‰ˆï¼‰"""
    
    def __init__(self, vehicle_id):
        self.vehicle_id = vehicle_id
        self.save_dir = f'output/camera_images/vehicle_{vehicle_id}'
        os.makedirs(self.save_dir, exist_ok=True)
        
        # åˆå§‹åŒ–è§†é¢‘å†™å…¥çº¿ç¨‹
        self.video_thread = VideoWriterThread(vehicle_id)
        self.video_thread.start()
        
        # åˆå§‹åŒ–æ•°æ®æ–‡ä»¶
        self.data_file = open(f'{self.save_dir}/vehicle_data.txt', 'w')
        self.data_file.write("frame_number,relative_time(s),x,y,z,speed(km/h),avg_depth(m)\n")
        
        # è®°å½•çŠ¶æ€
        self.is_recording = False
        self.has_recorded = False
        self.start_time = None
        self.frame_count = 0
        self.data_count = 0
        self.last_record_time = 0
        
        # æ·±åº¦æ•°æ®ç¼“å­˜
        self.last_depth_data = None
        
    def record_frame(self, rgb_image, depth_image, vehicle):
        """è®°å½•è§†é¢‘å¸§å’Œè½¦è¾†æ•°æ®"""
        if not self.is_recording:
            return
            
        # å¸§è®¡æ•°å™¨é€’å¢
        self.frame_count += 1
        
        # è½¬æ¢RGBå›¾åƒæ ¼å¼
        rgb_array = np.frombuffer(rgb_image.raw_data, dtype=np.uint8)
        rgb_array = np.reshape(rgb_array, (rgb_image.height, rgb_image.width, 4))
        rgb_array = rgb_array[:, :, :3]  # å»é™¤alphaé€šé“
        rgb_array = rgb_array[:, :, ::-1]  # ä»RGBè½¬æ¢ä¸ºBGR
        
        # å¤„ç†æ·±åº¦å›¾åƒ
        depth_meters = self._convert_depth_image(depth_image)
        self.last_depth_data = depth_meters  # ç¼“å­˜æ·±åº¦æ•°æ®
        
        # ä¸ºè§†é¢‘ç”Ÿæˆä¼˜åŒ–çš„æ·±åº¦å¯è§†åŒ–
        depth_vis = self._create_depth_visualization(depth_meters)
        
        # æ·»åŠ å¸§åˆ°è§†é¢‘çº¿ç¨‹é˜Ÿåˆ—
        self.video_thread.add_frame(rgb_array, depth_vis)
        
        # æ§åˆ¶æ•°æ®è®°å½•é¢‘ç‡ï¼ˆæ¯ç§’5æ¬¡ï¼‰
        current_time = time.time()
        if current_time - self.last_record_time >= 0.2:
            self._record_vehicle_data(vehicle, depth_image)
            self.last_record_time = current_time
    
    def _convert_depth_image(self, depth_image):
        """ä¼˜åŒ–æ·±åº¦å›¾åƒè½¬æ¢é€»è¾‘"""
        # ç›´æ¥ä½¿ç”¨CARLAçš„æ·±åº¦è½¬æ¢å‡½æ•°
        depth_array = np.frombuffer(depth_image.raw_data, dtype=np.float32)
        depth_array = np.reshape(depth_array, (depth_image.height, depth_image.width))
        return depth_array
    
    def _create_depth_visualization(self, depth_meters):
        """åˆ›å»ºæ·±åº¦å¯è§†åŒ–å›¾åƒ"""
        # é™åˆ¶æ·±åº¦èŒƒå›´åœ¨0-50ç±³å†…ï¼Œå¢å¼ºè§†è§‰æ•ˆæœ
        depth_vis = np.clip(depth_meters, 0, 50)
        
        # å½’ä¸€åŒ–åˆ°0-255èŒƒå›´
        depth_vis = (depth_vis / 50 * 255).astype(np.uint8)
        return depth_vis
    
    def _record_vehicle_data(self, vehicle, depth_image):
        """è®°å½•è½¦è¾†ä½ç½®å’Œé€Ÿåº¦æ•°æ®ï¼ŒåŒ…å«æ·±åº¦ä¿¡æ¯"""
        try:
            location = vehicle.get_location()
            velocity = vehicle.get_velocity()
            speed = 3.6 * math.sqrt(velocity.x**2 + velocity.y**2)  # å¿½ç•¥zè½´
            
            # è®¡ç®—ç›¸å¯¹æ—¶é—´
            relative_time = self.frame_count / FPS
            
            # è®¡ç®—å¹³å‡æ·±åº¦
            avg_depth = -1.0
            if self.last_depth_data is not None:
                # åªè®¡ç®—å›¾åƒä¸­å¿ƒåŒºåŸŸçš„æ·±åº¦
                center_region = self.last_depth_data[
                    depth_image.height//4:3*depth_image.height//4,
                    depth_image.width//4:3*depth_image.width//4
                ]
                avg_depth = np.mean(center_region)
            
            self.data_count += 1
            self.data_file.write(
                f"{self.frame_count},"
                f"{relative_time:.3f},"
                f"{location.x:.3f},"
                f"{location.y:.3f},"
                f"{location.z:.3f},"
                f"{speed:.2f},"
                f"{avg_depth:.2f}\n"
            )
            self.data_file.flush()
        except Exception as e:
            print(f"âš ï¸ Error recording vehicle data: {e}")
    
    def start_recording(self):
        """å¼€å§‹è®°å½•"""
        if not self.has_recorded:
            self.is_recording = True
            self.has_recorded = True
            self.start_time = time.time()
            self.frame_count = 0
            self.data_count = 0
            self.last_record_time = time.time()
            print(f"âºï¸ Started recording for vehicle {self.vehicle_id}")
    
    def stop_recording(self):
        """åœæ­¢è®°å½•"""
        if self.is_recording:
            self.is_recording = False
            duration = (time.time() - self.start_time) if self.start_time else 0
            print(f"â¹ï¸ Stopping recording for vehicle {self.vehicle_id}. Duration: {duration:.2f}s")
            
            # åœæ­¢è§†é¢‘çº¿ç¨‹
            self.video_thread.stop()
            self.data_file.close()

class VehicleCameraManager:
    """è½¦è¾†æ‘„åƒå¤´ç®¡ç†å™¨ï¼ˆä¼˜åŒ–ç‰ˆï¼‰"""

    def __init__(self, vehicle):
        self.vehicle = vehicle
        self.rgb_sensor = None
        self.depth_sensor = None
        self.recorded_positions = set()
        self.recorder = VehicleRecorder(vehicle.id)
        self.world = vehicle.get_world()
        self.rgb_queue = Queue(maxsize=5)
        self.depth_queue = Queue(maxsize=5)
        
        # è®°å½•çŠ¶æ€æ§åˆ¶
        self.was_on_street = False
        self.consecutive_off_street = 0
        self.max_off_street_frames = 30  # æœ€å¤§å…è®¸ç¦»å¼€é“è·¯çš„å¸§æ•°ï¼ˆ1ç§’ï¼‰
        self.frame_counter = 0  # ç”¨äºæ§åˆ¶æ£€æŸ¥é¢‘ç‡
        
        # åˆå§‹åŒ–RGBæ‘„åƒå¤´
        rgb_bp = self.world.get_blueprint_library().find('sensor.camera.rgb')
        rgb_bp.set_attribute('image_size_x', str(IMAGE_WIDTH))
        rgb_bp.set_attribute('image_size_y', str(IMAGE_HEIGHT))
        rgb_bp.set_attribute('fov', '100')  # è§†é‡100åº¦

        # åˆå§‹åŒ–æ·±åº¦æ‘„åƒå¤´
        depth_bp = self.world.get_blueprint_library().find('sensor.camera.depth')
        depth_bp.set_attribute('image_size_x', str(IMAGE_WIDTH))
        depth_bp.set_attribute('image_size_y', str(IMAGE_HEIGHT))
        depth_bp.set_attribute('fov', '100')
        
        # è®¾ç½®æ·±åº¦æ ¼å¼
        if depth_bp.has_attribute('pixel_format'):
            depth_bp.set_attribute('pixel_format', 'PF_Depth')
        elif depth_bp.has_attribute('format'):
            depth_bp.set_attribute('format', 'PF_Depth')

        # å®‰è£…ä½ç½®
        transform = carla.Transform(carla.Location(x=2.5, z=0.7))
        
        try:
            # ç”ŸæˆRGBæ‘„åƒå¤´
            self.rgb_sensor = self.world.spawn_actor(rgb_bp, transform, attach_to=self.vehicle)
            
            # ç”Ÿæˆæ·±åº¦æ‘„åƒå¤´
            self.depth_sensor = self.world.spawn_actor(depth_bp, transform, attach_to=self.vehicle)

            # è®¾ç½®å›¾åƒå›è°ƒå‡½æ•°
            weak_self = weakref.ref(self)
            self.rgb_sensor.listen(lambda image: self._parse_rgb_image(weak_self, image))
            self.depth_sensor.listen(lambda image: self._parse_depth_image(weak_self, image))
            print(f"ğŸ“· Cameras attached to vehicle {vehicle.id}")
        except Exception as e:
            print(f"âŒ Failed to spawn cameras: {e}")

    @staticmethod
    def _parse_rgb_image(weak_self, image):
        """å¤„ç†RGBå›¾åƒ"""
        self = weak_self()
        if not self or not self.vehicle.is_alive:
            return
            
        try:
            self.rgb_queue.put(image)
            self._process_images()
        except Exception as e:
            print(f"âš ï¸ Error processing RGB image: {e}")

    @staticmethod
    def _parse_depth_image(weak_self, image):
        """å¤„ç†æ·±åº¦å›¾åƒ"""
        self = weak_self()
        if not self or not self.vehicle.is_alive:
            return
            
        try:
            self.depth_queue.put(image)
            self._process_images()
        except Exception as e:
            print(f"âš ï¸ Error processing depth image: {e}")

    def _process_images(self):
        """å¤„ç†æˆå¯¹çš„RGBå’Œæ·±åº¦å›¾åƒ"""
        # åªæœ‰å½“ä¸¤ä¸ªé˜Ÿåˆ—éƒ½æœ‰æ•°æ®æ—¶æ‰å¤„ç†
        while not self.rgb_queue.empty() and not self.depth_queue.empty():
            rgb_image = self.rgb_queue.get()
            depth_image = self.depth_queue.get()
            
            # è·å–å½“å‰è½¦è¾†ä½ç½®
            vehicle_location = self.vehicle.get_location()
            
            # æ¯5å¸§æ£€æŸ¥ä¸€æ¬¡ä½ç½®ï¼ˆä¼˜åŒ–æ€§èƒ½ï¼‰
            self.frame_counter += 1
            if self.frame_counter % 5 == 0:
                on_street = StreetMonitor.is_on_street(vehicle_location)
                
                # æ›´æ–°è¿ç»­ç¦»å¼€é“è·¯çš„å¸§æ•°
                if not on_street:
                    self.consecutive_off_street += 1
                else:
                    self.consecutive_off_street = 0
                
                # æ§åˆ¶è®°å½•çŠ¶æ€
                if on_street and not self.recorder.is_recording and not self.recorder.has_recorded:
                    # ç¬¬ä¸€æ¬¡è¿›å…¥é“è·¯ï¼Œå¼€å§‹è®°å½•
                    self.recorder.start_recording()
                    self.was_on_street = True
                elif self.recorder.is_recording and self.consecutive_off_street >= self.max_off_street_frames:
                    # è¿ç»­ç¦»å¼€é“è·¯è¶…è¿‡é˜ˆå€¼ï¼Œåœæ­¢è®°å½•
                    self.recorder.stop_recording()
                    print(f"ğŸš« Vehicle {self.vehicle.id} left street for too long, stopped recording")
            
            # å¦‚æœæ­£åœ¨è®°å½•ï¼Œå¤„ç†å¸§
            if self.recorder.is_recording:
                self.recorder.record_frame(rgb_image, depth_image, self.vehicle)
                
            # æ£€æŸ¥æ˜¯å¦åˆ°è¾¾éœ€è¦è®°å½•çš„xä½ç½®
            current_x = round(vehicle_location.x)
            target_positions = [80, 70, 60, 50, 40, 30, 20, 10, 0]
            for target_x in target_positions:
                if (abs(current_x - target_x) <= 0.5 and 
                    target_x not in self.recorded_positions):
                    self._save_image_and_metadata(rgb_image, depth_image, vehicle_location, target_x)
                    self.recorded_positions.add(target_x)
                    
            # æ¸…ç†é˜Ÿåˆ—
            self.rgb_queue.task_done()
            self.depth_queue.task_done()

    def _save_image_and_metadata(self, rgb_image, depth_image, vehicle_location, target_x):
        """ä¿å­˜å›¾ç‰‡å’Œå…ƒæ•°æ®ï¼ˆåŒ…å«æ·±åº¦ä¿¡æ¯ï¼‰"""
        try:
            save_dir = f'output/camera_images/vehicle_{self.vehicle.id}'
            os.makedirs(save_dir, exist_ok=True)

            # è·å–ç›¸æœºå‚æ•°
            camera_transform = self.rgb_sensor.get_transform()
            metadata = {
                'timestamp': time.time(),
                'camera': {
                    'x': camera_transform.location.x,
                    'y': camera_transform.location.y,
                    'z': camera_transform.location.z,
                    'yaw': camera_transform.rotation.yaw,
                    'fov': 100,
                    'max_range': 30.0
                },
                'vehicle': {
                    'id': self.vehicle.id,
                    'x': vehicle_location.x,
                    'y': vehicle_location.y,
                    'z': vehicle_location.z,
                    'speed': 3.6 * math.sqrt(self.vehicle.get_velocity().x**2 + self.vehicle.get_velocity().y**2)
                }
            }

            # ä¿å­˜å…ƒæ•°æ®ä¸ºJSONæ–‡ä»¶
            metadata_path = f'{save_dir}/x{target_x}_meta.json'
            with open(metadata_path, 'w') as f:
                json.dump(metadata, f, indent=2)
            
            # ä¿å­˜RGBå›¾ç‰‡
            rgb_image.save_to_disk(f'{save_dir}/x{target_x}_rgb.png')
            
            # ä¿å­˜æ·±åº¦æ•°æ®ï¼ˆè½¬æ¢ä¸ºç±³ï¼‰
            depth_meters = self.recorder._convert_depth_image(depth_image)
            np.save(f'{save_dir}/x{target_x}_depth.npy', depth_meters)
            
            print(f"ğŸ’¾ Saved data at x={target_x} for sensor vehicle {self.vehicle.id}")
        except Exception as e:
            print(f"âš ï¸ Error saving image and metadata: {e}")

def generate_sensor_spawn_points():
    """ä¸ºæ„ŸçŸ¥è½¦è¾†ç”Ÿæˆä¼˜åŒ–çš„ç”Ÿæˆç‚¹ï¼ˆåˆ†å¸ƒåœ¨é“è·¯å³ä¾§è½¦é“ï¼‰"""
    sensor_spawn_points = []
    
    # å°†é“è·¯åˆ†ä¸ºä¸‰ä¸ªåŒºåŸŸ
    front_count = 4  # å‰æ–¹åŒºåŸŸ
    middle_count = 4  # ä¸­é—´åŒºåŸŸ
    rear_count = 2   # åæ–¹åŒºåŸŸ
    
    # å‰æ–¹åŒºåŸŸï¼šx=80åˆ°x=50
    for i in range(front_count):
        x = 80 - (i * SENSOR_VEHICLE_SPACING) - random.uniform(0, 2)
        spawn_point = carla.Transform(
            carla.Location(x=x, y=RIGHT_LANE_Y, z=0.1),
            carla.Rotation(yaw=180)
        )
        sensor_spawn_points.append(spawn_point)
    
    # ä¸­é—´åŒºåŸŸï¼šx=50åˆ°x=20
    for i in range(middle_count):
        x = 50 - (i * SENSOR_VEHICLE_SPACING) - random.uniform(0, 2)
        spawn_point = carla.Transform(
            carla.Location(x=x, y=RIGHT_LANE_Y, z=0.1),
            carla.Rotation(yaw=180)
        )
        sensor_spawn_points.append(spawn_point)
    
    # åæ–¹åŒºåŸŸï¼šx=20åˆ°x=-10
    for i in range(rear_count):
        x = 20 - (i * SENSOR_VEHICLE_SPACING) - random.uniform(0, 2)
        spawn_point = carla.Transform(
            carla.Location(x=x, y=RIGHT_LANE_Y, z=0.1),
            carla.Rotation(yaw=180)
        )
        sensor_spawn_points.append(spawn_point)
    
    return sensor_spawn_points

def generate_normal_spawn_points():
    """ä¸ºæ™®é€šè½¦è¾†ç”Ÿæˆå¯†é›†çš„ç”Ÿæˆç‚¹ï¼ˆé›†ä¸­åœ¨å·¦ä¾§è½¦é“ï¼‰"""
    spawn_points = []
    road_length = STREET_START.x - STREET_END.x  # 90ç±³
    
    # è®¡ç®—å·¦è½¦é“æœ€å¤§è½¦è¾†æ•°ï¼ˆæ‹¥æŒ¤äº¤é€šé—´è·0.5ç±³ï¼‰
    max_left_vehicles = int(road_length / (VEHICLE_LENGTH + 0.5))
    
    # ä¸ºå·¦è½¦é“ç”Ÿæˆå¯†é›†çš„ç”Ÿæˆç‚¹
    for i in range(max_left_vehicles):
        x = STREET_START.x - (i * (VEHICLE_LENGTH + 0.5)) - random.uniform(0, 1)
        spawn_point = carla.Transform(
            carla.Location(x=x, y=LEFT_LANE_Y, z=0.1),
            carla.Rotation(yaw=180)
        )
        spawn_points.append(spawn_point)
    
    # ä¸ºå³è½¦é“ç”Ÿæˆå°‘é‡æ™®é€šè½¦è¾†ï¼ˆé¿å…é®æŒ¡æ„ŸçŸ¥è½¦è¾†ï¼‰
    for i in range(5):  # å³è½¦é“æœ€å¤š5è¾†è½¦
        x = STREET_START.x - (road_length * 0.8) - (i * (VEHICLE_LENGTH + 10))
        spawn_point = carla.Transform(
            carla.Location(x=x, y=RIGHT_LANE_Y, z=0.1),
            carla.Rotation(yaw=180)
        )
        spawn_points.append(spawn_point)
    
    return spawn_points

def spawn_parked_vehicles(world):
    """åœ¨æŒ‡å®šä½ç½®ç”Ÿæˆ5è¾†è¿åœè½¦è¾†"""
    parked_vehicles = []
    vehicle_blueprints = world.get_blueprint_library().filter('vehicle.*')
    
    # åªå…è®¸å°æ±½è½¦ç±»å‹
    allowed_types = [
        'vehicle.audi.a2', 'vehicle.audi.tt', 'vehicle.bmw.grandtourer',
        'vehicle.chevrolet.impala', 'vehicle.citroen.c3', 'vehicle.ford.mustang',
        'vehicle.jeep.wrangler_rubicon', 'vehicle.mercedes.coupe_2020',
        'vehicle.mini.cooperst', 'vehicle.tesla.model3', 'vehicle.toyota.prius'
    ]
    vehicle_blueprints = [bp for bp in vehicle_blueprints if bp.id in allowed_types]

    # è·å–åœè½¦ä½ä½ç½®
    parking_spots = StreetMonitor.calculate_parking_positions()

    for i, spot in enumerate(parking_spots):
        blueprint = random.choice(vehicle_blueprints)
        if blueprint.has_attribute('color'):
            color = random.choice(blueprint.get_attribute('color').recommended_values)
            blueprint.set_attribute('color', color)

        # å°è¯•ç”Ÿæˆè½¦è¾†
        try:
            vehicle = world.spawn_actor(blueprint, spot)
            if vehicle is not None:
                parked_vehicles.append(vehicle)
                vehicle.set_autopilot(False)
                vehicle.set_simulate_physics(False)
        except Exception as e:
            print(f"âš ï¸ Failed to spawn parked vehicle: {e}")

    return parked_vehicles

def spawn_moving_vehicles(world, traffic_manager):
    """åœ¨æŒ‡å®šé“è·¯ä¸Šç”Ÿæˆè¿åŠ¨è½¦è¾†"""
    moving_vehicles = []
    camera_managers = []
    vehicle_blueprints = world.get_blueprint_library().filter('vehicle.*')
    
    # åªå…è®¸å°æ±½è½¦ç±»å‹
    allowed_types = [
        'vehicle.audi.a2', 'vehicle.audi.tt', 'vehicle.bmw.grandtourer',
        'vehicle.chevrolet.impala', 'vehicle.citroen.c3', 'vehicle.ford.mustang',
        'vehicle.jeep.wrangler_rubicon', 'vehicle.mercedes.coupe_2020',
        'vehicle.mini.cooperst', 'vehicle.tesla.model3', 'vehicle.toyota.prius'
    ]
    vehicle_blueprints = [bp for bp in vehicle_blueprints if bp.id in allowed_types]

    # ç”Ÿæˆæ„ŸçŸ¥è½¦è¾†çš„ä¼˜åŒ–ç”Ÿæˆç‚¹
    sensor_spawn_points = generate_sensor_spawn_points()
    
    # ç”Ÿæˆæ„ŸçŸ¥è½¦è¾†
    for spawn_point in sensor_spawn_points:
        if len(moving_vehicles) >= NUM_SENSOR_VEHICLES:
            break
            
        blueprint = random.choice(vehicle_blueprints)
        if blueprint.has_attribute('color'):
            color = random.choice(blueprint.get_attribute('color').recommended_values)
            blueprint.set_attribute('color', color)

        try:
            vehicle = world.spawn_actor(blueprint, spawn_point)
            if vehicle is not None:
                moving_vehicles.append(vehicle)
                vehicle.set_autopilot(True)
                
                # åº”ç”¨æ²¹é—¨æ§åˆ¶ç¡®ä¿è½¦è¾†ç§»åŠ¨
                vehicle.apply_control(carla.VehicleControl(throttle=0.7, steer=0.0))
                
                # äº¤é€šç®¡ç†å™¨è®¾ç½®
                traffic_manager.vehicle_percentage_speed_difference(vehicle, 0)
                traffic_manager.distance_to_leading_vehicle(vehicle, 1.5)
                traffic_manager.auto_lane_change(vehicle, False)
                traffic_manager.keep_right_rule_percentage(vehicle, 100)
                
                # å®‰è£…æ‘„åƒå¤´
                camera_managers.append(VehicleCameraManager(vehicle))
        except Exception as e:
            print(f"âš ï¸ Failed to spawn sensor vehicle: {e}")

    # ç”Ÿæˆæ™®é€šè½¦è¾†çš„ç”Ÿæˆç‚¹
    normal_spawn_points = generate_normal_spawn_points()
    
    # ç”Ÿæˆæ™®é€šè½¦è¾†
    for i, spawn_point in enumerate(normal_spawn_points):
        if len(moving_vehicles) >= NUM_SENSOR_VEHICLES + NUM_NORMAL_VEHICLES:
            break
            
        blueprint = random.choice(vehicle_blueprints)
        if blueprint.has_attribute('color'):
            color = random.choice(blueprint.get_attribute('color').recommended_values)
            blueprint.set_attribute('color', color)

        try:
            vehicle = world.spawn_actor(blueprint, spawn_point)
            if vehicle is not None:
                moving_vehicles.append(vehicle)
                vehicle.set_autopilot(True)
                
                # æ ¹æ®è½¦é“è®¾ç½®ä¸åŒçš„äº¤é€šè¡Œä¸º
                if abs(spawn_point.location.y - LEFT_LANE_Y) < 1.0:  # å·¦è½¦é“
                    vehicle.apply_control(carla.VehicleControl(throttle=0.3, steer=0.0))
                    traffic_manager.distance_to_leading_vehicle(vehicle, 1.0)
                    traffic_manager.keep_right_rule_percentage(vehicle, 0)
                else:  # å³è½¦é“
                    vehicle.apply_control(carla.VehicleControl(throttle=0.6, steer=0.0))
                    traffic_manager.distance_to_leading_vehicle(vehicle, 3.0)
                    traffic_manager.keep_right_rule_percentage(vehicle, 100)
        except Exception as e:
            print(f"âš ï¸ Failed to spawn normal vehicle: {e}")

    return moving_vehicles, camera_managers

def main():
    parked_vehicles = []
    moving_vehicles = []
    camera_managers = []
    
    try:
        # åˆ›å»ºè¾“å‡ºç›®å½•
        os.makedirs('output/camera_images', exist_ok=True)

        # è¿æ¥CARLAæœåŠ¡ç«¯
        client = carla.Client('localhost', 2000)
        client.set_timeout(20.0)
        world = client.get_world()

        # è®¾ç½®åŒæ­¥æ¨¡å¼
        settings = world.get_settings()
        settings.synchronous_mode = True
        settings.fixed_delta_seconds = 0.05
        world.apply_settings(settings)

        # è®¾ç½®å¤©æ°”
        weather = carla.WeatherParameters(cloudiness=80, precipitation=0, sun_altitude_angle=45)
        world.set_weather(weather)
        
        # è®¾ç½®çº¢ç»¿ç¯
        setup_traffic_light(world)
        
        # åˆå§‹åŒ–äº¤é€šç®¡ç†å™¨
        traffic_manager = client.get_trafficmanager()
        traffic_manager.set_synchronous_mode(True)
        traffic_manager.set_global_distance_to_leading_vehicle(1.0)
        traffic_manager.set_hybrid_physics_mode(True)
        traffic_manager.set_random_device_seed(42)

        # ç”Ÿæˆè¿åœè½¦è¾†
        parked_vehicles = spawn_parked_vehicles(world)

        # ç­‰å¾…1ç§’è®©è½¦è¾†ç¨³å®š
        for _ in range(20):
            world.tick()

        # ç”Ÿæˆè¿åŠ¨è½¦è¾†
        moving_vehicles, camera_managers = spawn_moving_vehicles(world, traffic_manager)

        # ä¸»å¾ªç¯
        start_time = time.time()
        last_status_time = time.time()
        frame_count = 0
        
        print(f"\nğŸš¦ Simulation started on road from x={STREET_START.x} to x={STREET_END.x}")
        
        while time.time() - start_time < SIMULATION_TIME:
            # æ§åˆ¶å¸§ç‡
            current_time = time.time()
            
            # æ¯100å¸§æ˜¾ç¤ºä¸€æ¬¡çŠ¶æ€
            frame_count += 1
            if frame_count % 100 == 0:
                print(f"â±ï¸ Frame: {frame_count}, Time: {current_time - start_time:.1f}s")
            
            # æ¯10ç§’æ˜¾ç¤ºäº¤é€šçŠ¶æ€
            if current_time - last_status_time > 10:
                last_status_time = current_time
                
                # è®¡ç®—æ´»è·ƒçš„è®°å½•æ•°é‡
                active_recordings = sum(1 for m in camera_managers 
                                       if m.recorder.is_recording and m.vehicle.is_alive)
                
                print(f"ğŸ“Š Active recordings: {active_recordings}/{len(camera_managers)}")
            
            # æ¨è¿›ä»¿çœŸ
            world.tick()
            
        print("\nğŸ Simulation finished")

    except KeyboardInterrupt:
        print("\nâ¹ï¸ Simulation stopped by user")
    except Exception as e:
        print(f"âŒ Error occurred: {str(e)}")
        import traceback
        traceback.print_exc()
    finally:
        # æ¸…ç†é˜¶æ®µ
        print("ğŸ§¹ Cleaning up...")

        # åœæ­¢æ‰€æœ‰è®°å½•å™¨
        for manager in camera_managers:
            try:
                if manager.recorder.is_recording:
                    manager.recorder.stop_recording()
            except:
                pass

        # æ¢å¤å¼‚æ­¥æ¨¡å¼
        try:
            settings = world.get_settings()
            settings.synchronous_mode = False
            world.apply_settings(settings)
        except:
            pass

        # é”€æ¯æ‰€æœ‰æ‘„åƒå¤´
        for manager in camera_managers:
            try:
                if manager.rgb_sensor and manager.rgb_sensor.is_alive:
                    manager.rgb_sensor.destroy()
                if manager.depth_sensor and manager.depth_sensor.is_alive:
                    manager.depth_sensor.destroy()
            except:
                pass

        # é”€æ¯æ‰€æœ‰è½¦è¾†
        actor_list = parked_vehicles + moving_vehicles
        for actor in actor_list:
            try:
                if actor.is_alive:
                    actor.destroy()
            except:
                pass
        
        time.sleep(1.0)
        print("âœ… Cleanup completed")

if __name__ == '__main__':
    main()